{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Approaches to Defining Neural Networks with Keras and TensorFlow\n",
    "\n",
    "[TensorFlow](https://www.tensorflow.org/) 2.0 came with many new exciting updates. One of these updates was full integration with the very popular [Keras API](https://keras.io/) for developing deep learning models. Before TensorFlow 2.0, you had two install TensorfFlow and Keras separately. Now, Keras comes as a submodule of TensorFlow (*i.e.*, tensorflow.keras). We will be using Keras and TensorFlow on the majority of tutorials in this class. There are 3 ways to define Neural Networks with Keras. In this tutorial we will cover these different ways.\n",
    "\n",
    "The learning goals of this tutorial are:\n",
    "    - Introduce the Keras sequential API, functional API and model subclassing methods for defining neural networks;\n",
    "    - Illustrate a simple classiifcation problem using the Iris dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Python Libraries \n",
    "\n",
    "If you get an error that a library is not installed, most libraries you can stall on a jupyter notebook by creating a new cell and typing:\n",
    "\n",
    "- *! pip install library_name*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # Function to convert labels to one-hot encoding\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.datasets import load_iris  # Function for loading the Iris dataset\n",
    "from sklearn.model_selection import train_test_split # Function for splitting the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset and return to the defined variable \n",
    "dataset = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load iris data into a DataFrame\n",
    "dframe = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "# add \"target_label\" column to the dataset and name it \"label\"\n",
    "dframe['labels'] = dataset.target.astype(int) # Labels are represented as integers\n",
    "# use of String label\n",
    "dframe['label_names'] = dframe.labels.replace(dict(enumerate(dataset.target_names)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>labels</th>\n",
       "      <th>label_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   labels label_names  \n",
       "0       0      setosa  \n",
       "1       0      setosa  \n",
       "2       0      setosa  \n",
       "3       0      setosa  \n",
       "4       0      setosa  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prints the 5 first rows/samples of the dataset\n",
    "dframe.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      labels  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generates a short description of the dataset (missing values, mean values, etc.)\n",
    "dframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(dframe[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
    "Y = np.asarray(dframe['labels'])\n",
    "Xtrain,Xtest,Ytrain,Ytest=train_test_split(X,Y,test_size=0.25,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation and Test Sets Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38, 4)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the features and labels from the dataset \n",
    "X = np.asarray(dframe[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']])\n",
    "Y = np.asarray(dframe['labels'])\n",
    "#print(X)\n",
    "# First we will shuffle the samples\n",
    "indexes = np.arange(X.shape[0])\n",
    "np.random.shuffle(indexes)\n",
    "X = X[indexes,:]\n",
    "Y = Y[indexes]\n",
    "\n",
    "# Then, we split our data into train/val/test sets\n",
    "train_split = np.int(0.5*Y.size)\n",
    "val_split = np.int(0.75*Y.size)\n",
    "\n",
    "X_train = X[:train_split,:]\n",
    "Y_train = Y[:train_split]\n",
    "\n",
    "X_val = X[train_split:val_split,:]\n",
    "Y_val = Y[train_split:val_split]\n",
    "\n",
    "X_test = X[val_split:,:]\n",
    "Y_test = Y[val_split:]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max data normalization\n",
    "x_train_min = X_train.min(axis = 0, keepdims = True)\n",
    "x_train_max = X_train.max(axis = 0, keepdims = True)\n",
    "\n",
    "X_train = (X_train - x_train_min)/(x_train_max - x_train_min)\n",
    "X_val = (X_val - x_train_min)/(x_train_max - x_train_min)\n",
    "X_test = (X_test - x_train_min)/(x_train_max - x_train_min)\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "#Activity suggestion:\n",
    "# 1. Change the min-max normalization above by standardization ((X - mean)/(std))\n",
    "# 2. Don't normalize the data and see what happens\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Representing Labels using one-hot-ecoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train[:5]:\n",
      "[2 0 0 0 0]\n",
      "\n",
      "Y_oh_train[:5]=\n",
      "[[0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "k = np.unique(Y).size\n",
    "Y_oh_train = to_categorical(Y_train, k) \n",
    "Y_oh_val = to_categorical(Y_val, k) \n",
    "Y_oh_test = to_categorical(Y_test, k)\n",
    "# Displaying the 5 first elemnts\n",
    "print('Y_train[:5]:')\n",
    "print(Y_train[:5])\n",
    "print('\\nY_oh_train[:5]=')\n",
    "print(Y_oh_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train :  (75, 4)\n",
      "Size of X_val :  (37, 4)\n",
      "Size of X_test :  (38, 4)\n"
     ]
    }
   ],
   "source": [
    "print( \"Size of X_train : \" , X_train.shape)\n",
    "print( \"Size of X_val : \" , X_val.shape)\n",
    "print( \"Size of X_test : \" , X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Approaches for Defining Neural Networks\n",
    "\n",
    "### 1. The Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "layer1 (Dense)               (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "layer2 (Dense)               (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "layer3 (Dense)               (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "# Passing a list of layers to the constructor\n",
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(5, activation='relu', input_shape=(4,) , name = \"layer1\"),\n",
    "    tf.keras.layers.Dense(10, activation='relu' , name = \"layer2\"),\n",
    "    tf.keras.layers.Dense(3, activation='softmax', name = \"layer3\"),\n",
    "])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. The Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 4)]               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 5)                 25        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                60        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 33        \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "# This returns a tensor\n",
    "input_tensor = tf.keras.layers.Input(shape=(4,))\n",
    "# A layer instance is callable on a tensor, and returns a tensor\n",
    "x1 = tf.keras.layers.Dense(5, activation='relu')(input_tensor)\n",
    "x2 = tf.keras.layers.Dense(10, activation='relu')(x1)\n",
    "out_tensor = tf.keras.layers.Dense(3, activation='softmax')(x2)\n",
    "# This creates a model that includes\n",
    "# the Input layer and three Dense layers\n",
    "model = Model(inputs=input_tensor, outputs=out_tensor)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Subclassing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_neural_network\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              multiple                  25        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  60        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  33        \n",
      "=================================================================\n",
      "Total params: 118\n",
      "Trainable params: 118\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class MyNeuralNetwork(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(MyNeuralNetwork, self).__init__(**kwargs)\n",
    "        self.dense1 = tf.keras.layers.Dense(5, activation='relu', )\n",
    "        self.dense2 = tf.keras.layers.Dense(10, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(3, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x1 = self.dense1(inputs)\n",
    "        x2 = self.dense2(x1)\n",
    "        out_tensor = self.dense3(x2)\n",
    "        return out_tensor\n",
    "model = MyNeuralNetwork()\n",
    "model.build(input_shape = (None,4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy', metrics=['accuracy']) # compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "2/2 [==============================] - 2s 1s/step - loss: 1.2928 - accuracy: 0.3724 - val_loss: 1.3957 - val_accuracy: 0.3514\n",
      "Epoch 2/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2753 - accuracy: 0.3932 - val_loss: 1.3873 - val_accuracy: 0.3514\n",
      "Epoch 3/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2705 - accuracy: 0.3880 - val_loss: 1.3785 - val_accuracy: 0.3784\n",
      "Epoch 4/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.2806 - accuracy: 0.3672 - val_loss: 1.3701 - val_accuracy: 0.3784\n",
      "Epoch 5/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.2671 - accuracy: 0.3917 - val_loss: 1.3623 - val_accuracy: 0.3784\n",
      "Epoch 6/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.2651 - accuracy: 0.3969 - val_loss: 1.3547 - val_accuracy: 0.3784\n",
      "Epoch 7/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.2523 - accuracy: 0.4125 - val_loss: 1.3473 - val_accuracy: 0.3784\n",
      "Epoch 8/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2566 - accuracy: 0.4021 - val_loss: 1.3400 - val_accuracy: 0.3514\n",
      "Epoch 9/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.2475 - accuracy: 0.4073 - val_loss: 1.3332 - val_accuracy: 0.3514\n",
      "Epoch 10/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2479 - accuracy: 0.3969 - val_loss: 1.3266 - val_accuracy: 0.3514\n",
      "Epoch 11/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.2389 - accuracy: 0.4021 - val_loss: 1.3203 - val_accuracy: 0.3514\n",
      "Epoch 12/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.2326 - accuracy: 0.4021 - val_loss: 1.3141 - val_accuracy: 0.3514\n",
      "Epoch 13/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.2353 - accuracy: 0.3969 - val_loss: 1.3081 - val_accuracy: 0.3514\n",
      "Epoch 14/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2297 - accuracy: 0.4021 - val_loss: 1.3024 - val_accuracy: 0.3514\n",
      "Epoch 15/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.2211 - accuracy: 0.4073 - val_loss: 1.2968 - val_accuracy: 0.3514\n",
      "Epoch 16/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.2245 - accuracy: 0.3724 - val_loss: 1.2914 - val_accuracy: 0.3514\n",
      "Epoch 17/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.2167 - accuracy: 0.3932 - val_loss: 1.2863 - val_accuracy: 0.3514\n",
      "Epoch 18/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.2116 - accuracy: 0.3932 - val_loss: 1.2811 - val_accuracy: 0.3243\n",
      "Epoch 19/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.2070 - accuracy: 0.3932 - val_loss: 1.2759 - val_accuracy: 0.3243\n",
      "Epoch 20/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.2118 - accuracy: 0.3598 - val_loss: 1.2708 - val_accuracy: 0.3243\n",
      "Epoch 21/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.2059 - accuracy: 0.3650 - val_loss: 1.2661 - val_accuracy: 0.2973\n",
      "Epoch 22/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.2057 - accuracy: 0.3546 - val_loss: 1.2618 - val_accuracy: 0.2973\n",
      "Epoch 23/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.2000 - accuracy: 0.3546 - val_loss: 1.2579 - val_accuracy: 0.2973\n",
      "Epoch 24/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1971 - accuracy: 0.3650 - val_loss: 1.2540 - val_accuracy: 0.2973\n",
      "Epoch 25/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1917 - accuracy: 0.3442 - val_loss: 1.2501 - val_accuracy: 0.2973\n",
      "Epoch 26/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1900 - accuracy: 0.3598 - val_loss: 1.2461 - val_accuracy: 0.2973\n",
      "Epoch 27/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1879 - accuracy: 0.3650 - val_loss: 1.2421 - val_accuracy: 0.2973\n",
      "Epoch 28/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1890 - accuracy: 0.3546 - val_loss: 1.2382 - val_accuracy: 0.2973\n",
      "Epoch 29/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1797 - accuracy: 0.3598 - val_loss: 1.2344 - val_accuracy: 0.2973\n",
      "Epoch 30/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1768 - accuracy: 0.3702 - val_loss: 1.2303 - val_accuracy: 0.2973\n",
      "Epoch 31/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1812 - accuracy: 0.3650 - val_loss: 1.2262 - val_accuracy: 0.2973\n",
      "Epoch 32/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1764 - accuracy: 0.3754 - val_loss: 1.2224 - val_accuracy: 0.2973\n",
      "Epoch 33/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1727 - accuracy: 0.3494 - val_loss: 1.2186 - val_accuracy: 0.2973\n",
      "Epoch 34/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1702 - accuracy: 0.3546 - val_loss: 1.2148 - val_accuracy: 0.2973\n",
      "Epoch 35/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1706 - accuracy: 0.3494 - val_loss: 1.2110 - val_accuracy: 0.2973\n",
      "Epoch 36/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1654 - accuracy: 0.3650 - val_loss: 1.2073 - val_accuracy: 0.3243\n",
      "Epoch 37/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1628 - accuracy: 0.3546 - val_loss: 1.2035 - val_accuracy: 0.3243\n",
      "Epoch 38/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1604 - accuracy: 0.3598 - val_loss: 1.1998 - val_accuracy: 0.3514\n",
      "Epoch 39/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1569 - accuracy: 0.3932 - val_loss: 1.1964 - val_accuracy: 0.3514\n",
      "Epoch 40/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1564 - accuracy: 0.3776 - val_loss: 1.1935 - val_accuracy: 0.3514\n",
      "Epoch 41/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1510 - accuracy: 0.3932 - val_loss: 1.1908 - val_accuracy: 0.3514\n",
      "Epoch 42/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1516 - accuracy: 0.4073 - val_loss: 1.1885 - val_accuracy: 0.3514\n",
      "Epoch 43/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1480 - accuracy: 0.4073 - val_loss: 1.1863 - val_accuracy: 0.3514\n",
      "Epoch 44/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1438 - accuracy: 0.3969 - val_loss: 1.1839 - val_accuracy: 0.3514\n",
      "Epoch 45/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1447 - accuracy: 0.4021 - val_loss: 1.1815 - val_accuracy: 0.3514\n",
      "Epoch 46/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1420 - accuracy: 0.4021 - val_loss: 1.1790 - val_accuracy: 0.3514\n",
      "Epoch 47/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.1410 - accuracy: 0.4021 - val_loss: 1.1765 - val_accuracy: 0.3514\n",
      "Epoch 48/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1409 - accuracy: 0.3865 - val_loss: 1.1740 - val_accuracy: 0.3784\n",
      "Epoch 49/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1403 - accuracy: 0.3865 - val_loss: 1.1717 - val_accuracy: 0.3784\n",
      "Epoch 50/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 1.1328 - accuracy: 0.4073 - val_loss: 1.1694 - val_accuracy: 0.3784\n",
      "Epoch 51/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1359 - accuracy: 0.3969 - val_loss: 1.1669 - val_accuracy: 0.3784\n",
      "Epoch 52/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1323 - accuracy: 0.3969 - val_loss: 1.1645 - val_accuracy: 0.3784\n",
      "Epoch 53/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1317 - accuracy: 0.3865 - val_loss: 1.1620 - val_accuracy: 0.3784\n",
      "Epoch 54/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1300 - accuracy: 0.3969 - val_loss: 1.1595 - val_accuracy: 0.3784\n",
      "Epoch 55/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1313 - accuracy: 0.3917 - val_loss: 1.1572 - val_accuracy: 0.3784\n",
      "Epoch 56/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.1268 - accuracy: 0.4073 - val_loss: 1.1551 - val_accuracy: 0.3784\n",
      "Epoch 57/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1269 - accuracy: 0.3917 - val_loss: 1.1531 - val_accuracy: 0.3784\n",
      "Epoch 58/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1233 - accuracy: 0.3969 - val_loss: 1.1512 - val_accuracy: 0.3784\n",
      "Epoch 59/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1200 - accuracy: 0.4021 - val_loss: 1.1490 - val_accuracy: 0.3784\n",
      "Epoch 60/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.1217 - accuracy: 0.4021 - val_loss: 1.1468 - val_accuracy: 0.3784\n",
      "Epoch 61/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1181 - accuracy: 0.4125 - val_loss: 1.1447 - val_accuracy: 0.3784\n",
      "Epoch 62/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 1.1175 - accuracy: 0.3917 - val_loss: 1.1425 - val_accuracy: 0.3784\n",
      "Epoch 63/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1154 - accuracy: 0.4021 - val_loss: 1.1404 - val_accuracy: 0.3784\n",
      "Epoch 64/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1117 - accuracy: 0.4125 - val_loss: 1.1384 - val_accuracy: 0.3784\n",
      "Epoch 65/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.1124 - accuracy: 0.4021 - val_loss: 1.1365 - val_accuracy: 0.3784\n",
      "Epoch 66/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.1102 - accuracy: 0.3917 - val_loss: 1.1346 - val_accuracy: 0.3784\n",
      "Epoch 67/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.1058 - accuracy: 0.4073 - val_loss: 1.1328 - val_accuracy: 0.3784\n",
      "Epoch 68/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.1065 - accuracy: 0.3917 - val_loss: 1.1308 - val_accuracy: 0.3784\n",
      "Epoch 69/300\n",
      "2/2 [==============================] - 0s 131ms/step - loss: 1.1032 - accuracy: 0.3917 - val_loss: 1.1288 - val_accuracy: 0.3784\n",
      "Epoch 70/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.1019 - accuracy: 0.4073 - val_loss: 1.1266 - val_accuracy: 0.3784\n",
      "Epoch 71/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 1.0960 - accuracy: 0.4073 - val_loss: 1.1241 - val_accuracy: 0.3784\n",
      "Epoch 72/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0986 - accuracy: 0.3917 - val_loss: 1.1214 - val_accuracy: 0.3784\n",
      "Epoch 73/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0963 - accuracy: 0.4021 - val_loss: 1.1188 - val_accuracy: 0.3784\n",
      "Epoch 74/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0942 - accuracy: 0.4177 - val_loss: 1.1162 - val_accuracy: 0.3784\n",
      "Epoch 75/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0918 - accuracy: 0.4021 - val_loss: 1.1137 - val_accuracy: 0.3784\n",
      "Epoch 76/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0922 - accuracy: 0.4392 - val_loss: 1.1113 - val_accuracy: 0.3784\n",
      "Epoch 77/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0893 - accuracy: 0.4481 - val_loss: 1.1090 - val_accuracy: 0.4054\n",
      "Epoch 78/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 1.0889 - accuracy: 0.4710 - val_loss: 1.1068 - val_accuracy: 0.4054\n",
      "Epoch 79/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0850 - accuracy: 0.4956 - val_loss: 1.1046 - val_accuracy: 0.4324\n",
      "Epoch 80/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0830 - accuracy: 0.5097 - val_loss: 1.1023 - val_accuracy: 0.4324\n",
      "Epoch 81/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0799 - accuracy: 0.5431 - val_loss: 1.0999 - val_accuracy: 0.4324\n",
      "Epoch 82/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 1.0798 - accuracy: 0.5504 - val_loss: 1.0975 - val_accuracy: 0.4324\n",
      "Epoch 83/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0760 - accuracy: 0.5660 - val_loss: 1.0950 - val_accuracy: 0.4324\n",
      "Epoch 84/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0724 - accuracy: 0.5660 - val_loss: 1.0922 - val_accuracy: 0.4865\n",
      "Epoch 85/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0727 - accuracy: 0.5697 - val_loss: 1.0892 - val_accuracy: 0.4865\n",
      "Epoch 86/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0693 - accuracy: 0.6083 - val_loss: 1.0862 - val_accuracy: 0.4865\n",
      "Epoch 87/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0667 - accuracy: 0.6031 - val_loss: 1.0830 - val_accuracy: 0.4865\n",
      "Epoch 88/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0658 - accuracy: 0.6261 - val_loss: 1.0799 - val_accuracy: 0.4865\n",
      "Epoch 89/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 1.0634 - accuracy: 0.6439 - val_loss: 1.0768 - val_accuracy: 0.4865\n",
      "Epoch 90/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0609 - accuracy: 0.6543 - val_loss: 1.0738 - val_accuracy: 0.4865\n",
      "Epoch 91/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0578 - accuracy: 0.6595 - val_loss: 1.0706 - val_accuracy: 0.4865\n",
      "Epoch 92/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 1.0559 - accuracy: 0.6580 - val_loss: 1.0675 - val_accuracy: 0.5135\n",
      "Epoch 93/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0499 - accuracy: 0.6788 - val_loss: 1.0642 - val_accuracy: 0.5135\n",
      "Epoch 94/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 1.0493 - accuracy: 0.6825 - val_loss: 1.0606 - val_accuracy: 0.5135\n",
      "Epoch 95/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0453 - accuracy: 0.6877 - val_loss: 1.0568 - val_accuracy: 0.5135\n",
      "Epoch 96/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 1.0432 - accuracy: 0.6773 - val_loss: 1.0529 - val_accuracy: 0.5405\n",
      "Epoch 97/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 1.0412 - accuracy: 0.7055 - val_loss: 1.0490 - val_accuracy: 0.5405\n",
      "Epoch 98/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0380 - accuracy: 0.7055 - val_loss: 1.0449 - val_accuracy: 0.5405\n",
      "Epoch 99/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0328 - accuracy: 0.7107 - val_loss: 1.0406 - val_accuracy: 0.5405\n",
      "Epoch 100/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0300 - accuracy: 0.7107 - val_loss: 1.0362 - val_accuracy: 0.5405\n",
      "Epoch 101/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0256 - accuracy: 0.7159 - val_loss: 1.0315 - val_accuracy: 0.5405\n",
      "Epoch 102/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 1.0225 - accuracy: 0.6951 - val_loss: 1.0268 - val_accuracy: 0.5405\n",
      "Epoch 103/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 1.0204 - accuracy: 0.7003 - val_loss: 1.0224 - val_accuracy: 0.5405\n",
      "Epoch 104/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0151 - accuracy: 0.7003 - val_loss: 1.0179 - val_accuracy: 0.5405\n",
      "Epoch 105/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 1.0112 - accuracy: 0.7055 - val_loss: 1.0136 - val_accuracy: 0.5405\n",
      "Epoch 106/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 1.0067 - accuracy: 0.7003 - val_loss: 1.0092 - val_accuracy: 0.5405\n",
      "Epoch 107/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 1.0028 - accuracy: 0.7107 - val_loss: 1.0047 - val_accuracy: 0.5676\n",
      "Epoch 108/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.9992 - accuracy: 0.6899 - val_loss: 1.0002 - val_accuracy: 0.5676\n",
      "Epoch 109/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9935 - accuracy: 0.7055 - val_loss: 0.9958 - val_accuracy: 0.5676\n",
      "Epoch 110/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9904 - accuracy: 0.7055 - val_loss: 0.9915 - val_accuracy: 0.5676\n",
      "Epoch 111/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9848 - accuracy: 0.7055 - val_loss: 0.9868 - val_accuracy: 0.5676\n",
      "Epoch 112/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.9817 - accuracy: 0.7055 - val_loss: 0.9819 - val_accuracy: 0.5676\n",
      "Epoch 113/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9770 - accuracy: 0.6951 - val_loss: 0.9769 - val_accuracy: 0.5676\n",
      "Epoch 114/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.9721 - accuracy: 0.7003 - val_loss: 0.9720 - val_accuracy: 0.5676\n",
      "Epoch 115/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9678 - accuracy: 0.7055 - val_loss: 0.9671 - val_accuracy: 0.5946\n",
      "Epoch 116/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.9638 - accuracy: 0.7144 - val_loss: 0.9621 - val_accuracy: 0.5946\n",
      "Epoch 117/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9550 - accuracy: 0.7352 - val_loss: 0.9569 - val_accuracy: 0.5946\n",
      "Epoch 118/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.9507 - accuracy: 0.7248 - val_loss: 0.9513 - val_accuracy: 0.5946\n",
      "Epoch 119/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.9484 - accuracy: 0.7196 - val_loss: 0.9457 - val_accuracy: 0.5946\n",
      "Epoch 120/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.9439 - accuracy: 0.7144 - val_loss: 0.9401 - val_accuracy: 0.5946\n",
      "Epoch 121/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9393 - accuracy: 0.7144 - val_loss: 0.9345 - val_accuracy: 0.5946\n",
      "Epoch 122/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.9343 - accuracy: 0.7144 - val_loss: 0.9288 - val_accuracy: 0.5946\n",
      "Epoch 123/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.9273 - accuracy: 0.7248 - val_loss: 0.9231 - val_accuracy: 0.5946\n",
      "Epoch 124/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.9230 - accuracy: 0.7144 - val_loss: 0.9172 - val_accuracy: 0.5946\n",
      "Epoch 125/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.9152 - accuracy: 0.7248 - val_loss: 0.9113 - val_accuracy: 0.5946\n",
      "Epoch 126/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.9122 - accuracy: 0.7196 - val_loss: 0.9053 - val_accuracy: 0.5946\n",
      "Epoch 127/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.9050 - accuracy: 0.7248 - val_loss: 0.8992 - val_accuracy: 0.5946\n",
      "Epoch 128/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.9006 - accuracy: 0.7196 - val_loss: 0.8931 - val_accuracy: 0.5946\n",
      "Epoch 129/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.8971 - accuracy: 0.7144 - val_loss: 0.8871 - val_accuracy: 0.5946\n",
      "Epoch 130/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8922 - accuracy: 0.7144 - val_loss: 0.8811 - val_accuracy: 0.5946\n",
      "Epoch 131/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.8842 - accuracy: 0.7092 - val_loss: 0.8754 - val_accuracy: 0.5946\n",
      "Epoch 132/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.8796 - accuracy: 0.7196 - val_loss: 0.8698 - val_accuracy: 0.5946\n",
      "Epoch 133/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8728 - accuracy: 0.7248 - val_loss: 0.8642 - val_accuracy: 0.5946\n",
      "Epoch 134/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8704 - accuracy: 0.7196 - val_loss: 0.8583 - val_accuracy: 0.5946\n",
      "Epoch 135/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.8661 - accuracy: 0.7248 - val_loss: 0.8520 - val_accuracy: 0.8108\n",
      "Epoch 136/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.8578 - accuracy: 0.7144 - val_loss: 0.8456 - val_accuracy: 0.8649\n",
      "Epoch 137/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.8542 - accuracy: 0.8235 - val_loss: 0.8392 - val_accuracy: 0.9189\n",
      "Epoch 138/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.8478 - accuracy: 0.8553 - val_loss: 0.8326 - val_accuracy: 0.9459\n",
      "Epoch 139/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.8415 - accuracy: 0.8783 - val_loss: 0.8259 - val_accuracy: 0.9459\n",
      "Epoch 140/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.8321 - accuracy: 0.8731 - val_loss: 0.8190 - val_accuracy: 0.9730\n",
      "Epoch 141/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.8288 - accuracy: 0.8887 - val_loss: 0.8117 - val_accuracy: 1.0000\n",
      "Epoch 142/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.8254 - accuracy: 0.9013 - val_loss: 0.8043 - val_accuracy: 0.9730\n",
      "Epoch 143/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.8138 - accuracy: 0.8976 - val_loss: 0.7968 - val_accuracy: 0.9459\n",
      "Epoch 144/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.8106 - accuracy: 0.8976 - val_loss: 0.7893 - val_accuracy: 0.9189\n",
      "Epoch 145/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.8058 - accuracy: 0.8449 - val_loss: 0.7816 - val_accuracy: 0.9189\n",
      "Epoch 146/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7934 - accuracy: 0.8131 - val_loss: 0.7741 - val_accuracy: 0.8919\n",
      "Epoch 147/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7903 - accuracy: 0.8131 - val_loss: 0.7669 - val_accuracy: 0.8919\n",
      "Epoch 148/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7818 - accuracy: 0.8078 - val_loss: 0.7600 - val_accuracy: 0.8919\n",
      "Epoch 149/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7787 - accuracy: 0.7990 - val_loss: 0.7532 - val_accuracy: 0.8649\n",
      "Epoch 150/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.7749 - accuracy: 0.7708 - val_loss: 0.7462 - val_accuracy: 0.8649\n",
      "Epoch 151/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7656 - accuracy: 0.7656 - val_loss: 0.7392 - val_accuracy: 0.8649\n",
      "Epoch 152/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.7563 - accuracy: 0.7671 - val_loss: 0.7321 - val_accuracy: 0.8649\n",
      "Epoch 153/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.7541 - accuracy: 0.7478 - val_loss: 0.7252 - val_accuracy: 0.8649\n",
      "Epoch 154/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.7462 - accuracy: 0.7634 - val_loss: 0.7186 - val_accuracy: 0.8649\n",
      "Epoch 155/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.7423 - accuracy: 0.7374 - val_loss: 0.7123 - val_accuracy: 0.8649\n",
      "Epoch 156/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7348 - accuracy: 0.7530 - val_loss: 0.7059 - val_accuracy: 0.8649\n",
      "Epoch 157/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.7286 - accuracy: 0.7530 - val_loss: 0.6997 - val_accuracy: 0.8649\n",
      "Epoch 158/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.7243 - accuracy: 0.7322 - val_loss: 0.6934 - val_accuracy: 0.8649\n",
      "Epoch 159/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.7151 - accuracy: 0.7426 - val_loss: 0.6867 - val_accuracy: 0.8649\n",
      "Epoch 160/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.7145 - accuracy: 0.7426 - val_loss: 0.6797 - val_accuracy: 0.8649\n",
      "Epoch 161/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7086 - accuracy: 0.7426 - val_loss: 0.6727 - val_accuracy: 0.8378\n",
      "Epoch 162/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.7031 - accuracy: 0.7374 - val_loss: 0.6657 - val_accuracy: 0.8378\n",
      "Epoch 163/300\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 0.7005 - accuracy: 0.7181 - val_loss: 0.6586 - val_accuracy: 0.8378\n",
      "Epoch 164/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6857 - accuracy: 0.7144 - val_loss: 0.6515 - val_accuracy: 0.8378\n",
      "Epoch 165/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.6820 - accuracy: 0.7144 - val_loss: 0.6445 - val_accuracy: 0.8378\n",
      "Epoch 166/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.6734 - accuracy: 0.7144 - val_loss: 0.6375 - val_accuracy: 0.8378\n",
      "Epoch 167/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6693 - accuracy: 0.7337 - val_loss: 0.6309 - val_accuracy: 0.8378\n",
      "Epoch 168/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.6644 - accuracy: 0.7374 - val_loss: 0.6244 - val_accuracy: 0.8378\n",
      "Epoch 169/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.6573 - accuracy: 0.7374 - val_loss: 0.6175 - val_accuracy: 0.8649\n",
      "Epoch 170/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6483 - accuracy: 0.7478 - val_loss: 0.6106 - val_accuracy: 0.8649\n",
      "Epoch 171/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.6481 - accuracy: 0.7478 - val_loss: 0.6044 - val_accuracy: 0.8649\n",
      "Epoch 172/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6318 - accuracy: 0.7530 - val_loss: 0.5990 - val_accuracy: 0.8649\n",
      "Epoch 173/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6330 - accuracy: 0.7567 - val_loss: 0.5941 - val_accuracy: 0.8649\n",
      "Epoch 174/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6283 - accuracy: 0.7656 - val_loss: 0.5889 - val_accuracy: 0.8649\n",
      "Epoch 175/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6216 - accuracy: 0.7812 - val_loss: 0.5838 - val_accuracy: 0.8649\n",
      "Epoch 176/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6222 - accuracy: 0.7656 - val_loss: 0.5791 - val_accuracy: 0.8649\n",
      "Epoch 177/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6109 - accuracy: 0.7708 - val_loss: 0.5742 - val_accuracy: 0.8649\n",
      "Epoch 178/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6044 - accuracy: 0.7812 - val_loss: 0.5696 - val_accuracy: 0.8649\n",
      "Epoch 179/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5983 - accuracy: 0.7901 - val_loss: 0.5655 - val_accuracy: 0.8649\n",
      "Epoch 180/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.5982 - accuracy: 0.8042 - val_loss: 0.5614 - val_accuracy: 0.8649\n",
      "Epoch 181/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5959 - accuracy: 0.8094 - val_loss: 0.5574 - val_accuracy: 0.8649\n",
      "Epoch 182/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.5891 - accuracy: 0.7990 - val_loss: 0.5536 - val_accuracy: 0.8649\n",
      "Epoch 183/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5856 - accuracy: 0.7938 - val_loss: 0.5496 - val_accuracy: 0.8649\n",
      "Epoch 184/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5845 - accuracy: 0.7938 - val_loss: 0.5456 - val_accuracy: 0.8649\n",
      "Epoch 185/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5712 - accuracy: 0.8094 - val_loss: 0.5418 - val_accuracy: 0.8649\n",
      "Epoch 186/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5783 - accuracy: 0.7938 - val_loss: 0.5383 - val_accuracy: 0.8649\n",
      "Epoch 187/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.5654 - accuracy: 0.8042 - val_loss: 0.5347 - val_accuracy: 0.8649\n",
      "Epoch 188/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5589 - accuracy: 0.8146 - val_loss: 0.5314 - val_accuracy: 0.8649\n",
      "Epoch 189/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5676 - accuracy: 0.8131 - val_loss: 0.5283 - val_accuracy: 0.8649\n",
      "Epoch 190/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5535 - accuracy: 0.8183 - val_loss: 0.5251 - val_accuracy: 0.8649\n",
      "Epoch 191/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5492 - accuracy: 0.8235 - val_loss: 0.5221 - val_accuracy: 0.8649\n",
      "Epoch 192/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.5538 - accuracy: 0.8219 - val_loss: 0.5192 - val_accuracy: 0.8649\n",
      "Epoch 193/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.5500 - accuracy: 0.8272 - val_loss: 0.5161 - val_accuracy: 0.8919\n",
      "Epoch 194/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5429 - accuracy: 0.8272 - val_loss: 0.5133 - val_accuracy: 0.8919\n",
      "Epoch 195/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.5371 - accuracy: 0.8376 - val_loss: 0.5108 - val_accuracy: 0.9189\n",
      "Epoch 196/300\n",
      "2/2 [==============================] - 0s 48ms/step - loss: 0.5378 - accuracy: 0.8376 - val_loss: 0.5087 - val_accuracy: 0.9189\n",
      "Epoch 197/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5289 - accuracy: 0.8360 - val_loss: 0.5066 - val_accuracy: 0.9189\n",
      "Epoch 198/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5325 - accuracy: 0.8835 - val_loss: 0.5042 - val_accuracy: 0.9189\n",
      "Epoch 199/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5256 - accuracy: 0.8872 - val_loss: 0.5015 - val_accuracy: 0.9189\n",
      "Epoch 200/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.5204 - accuracy: 0.9028 - val_loss: 0.4986 - val_accuracy: 0.9189\n",
      "Epoch 201/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5272 - accuracy: 0.8731 - val_loss: 0.4960 - val_accuracy: 0.9189\n",
      "Epoch 202/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.5290 - accuracy: 0.8783 - val_loss: 0.4934 - val_accuracy: 0.9189\n",
      "Epoch 203/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.5136 - accuracy: 0.8976 - val_loss: 0.4910 - val_accuracy: 0.9459\n",
      "Epoch 204/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.5148 - accuracy: 0.8924 - val_loss: 0.4883 - val_accuracy: 0.9459\n",
      "Epoch 205/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.5078 - accuracy: 0.8976 - val_loss: 0.4855 - val_accuracy: 0.9459\n",
      "Epoch 206/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.5049 - accuracy: 0.8924 - val_loss: 0.4829 - val_accuracy: 0.9459\n",
      "Epoch 207/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.5097 - accuracy: 0.8872 - val_loss: 0.4798 - val_accuracy: 0.9189\n",
      "Epoch 208/300\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.5063 - accuracy: 0.8924 - val_loss: 0.4767 - val_accuracy: 0.9189\n",
      "Epoch 209/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4960 - accuracy: 0.8835 - val_loss: 0.4739 - val_accuracy: 0.9189\n",
      "Epoch 210/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4985 - accuracy: 0.8835 - val_loss: 0.4718 - val_accuracy: 0.9459\n",
      "Epoch 211/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4946 - accuracy: 0.8924 - val_loss: 0.4699 - val_accuracy: 0.9459\n",
      "Epoch 212/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4998 - accuracy: 0.8872 - val_loss: 0.4677 - val_accuracy: 0.9459\n",
      "Epoch 213/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4929 - accuracy: 0.8872 - val_loss: 0.4657 - val_accuracy: 0.9459\n",
      "Epoch 214/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4861 - accuracy: 0.8872 - val_loss: 0.4636 - val_accuracy: 0.9459\n",
      "Epoch 215/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4937 - accuracy: 0.8976 - val_loss: 0.4615 - val_accuracy: 0.9459\n",
      "Epoch 216/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4904 - accuracy: 0.8783 - val_loss: 0.4595 - val_accuracy: 0.9459\n",
      "Epoch 217/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4812 - accuracy: 0.8835 - val_loss: 0.4577 - val_accuracy: 0.9459\n",
      "Epoch 218/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4809 - accuracy: 0.8783 - val_loss: 0.4555 - val_accuracy: 0.9459\n",
      "Epoch 219/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4786 - accuracy: 0.8887 - val_loss: 0.4527 - val_accuracy: 0.9459\n",
      "Epoch 220/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4716 - accuracy: 0.8783 - val_loss: 0.4498 - val_accuracy: 0.9459\n",
      "Epoch 221/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4743 - accuracy: 0.8924 - val_loss: 0.4466 - val_accuracy: 0.9459\n",
      "Epoch 222/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4770 - accuracy: 0.8976 - val_loss: 0.4436 - val_accuracy: 0.9189\n",
      "Epoch 223/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4710 - accuracy: 0.8783 - val_loss: 0.4409 - val_accuracy: 0.9189\n",
      "Epoch 224/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4674 - accuracy: 0.8835 - val_loss: 0.4385 - val_accuracy: 0.9189\n",
      "Epoch 225/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4709 - accuracy: 0.8783 - val_loss: 0.4361 - val_accuracy: 0.9189\n",
      "Epoch 226/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4690 - accuracy: 0.8694 - val_loss: 0.4338 - val_accuracy: 0.9189\n",
      "Epoch 227/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4646 - accuracy: 0.8590 - val_loss: 0.4319 - val_accuracy: 0.9189\n",
      "Epoch 228/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4564 - accuracy: 0.8747 - val_loss: 0.4302 - val_accuracy: 0.9189\n",
      "Epoch 229/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4516 - accuracy: 0.8783 - val_loss: 0.4288 - val_accuracy: 0.9189\n",
      "Epoch 230/300\n",
      "2/2 [==============================] - 0s 47ms/step - loss: 0.4546 - accuracy: 0.8924 - val_loss: 0.4276 - val_accuracy: 0.9459\n",
      "Epoch 231/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4600 - accuracy: 0.8872 - val_loss: 0.4262 - val_accuracy: 0.9459\n",
      "Epoch 232/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4596 - accuracy: 0.8924 - val_loss: 0.4249 - val_accuracy: 0.9459\n",
      "Epoch 233/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4565 - accuracy: 0.8976 - val_loss: 0.4235 - val_accuracy: 0.9459\n",
      "Epoch 234/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.4608 - accuracy: 0.8924 - val_loss: 0.4217 - val_accuracy: 0.9459\n",
      "Epoch 235/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4427 - accuracy: 0.8976 - val_loss: 0.4200 - val_accuracy: 0.9459\n",
      "Epoch 236/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4487 - accuracy: 0.8924 - val_loss: 0.4186 - val_accuracy: 0.9459\n",
      "Epoch 237/300\n",
      "2/2 [==============================] - 0s 53ms/step - loss: 0.4524 - accuracy: 0.8872 - val_loss: 0.4167 - val_accuracy: 0.9459\n",
      "Epoch 238/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.4430 - accuracy: 0.8924 - val_loss: 0.4146 - val_accuracy: 0.9459\n",
      "Epoch 239/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4456 - accuracy: 0.8976 - val_loss: 0.4128 - val_accuracy: 0.9459\n",
      "Epoch 240/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4297 - accuracy: 0.8976 - val_loss: 0.4113 - val_accuracy: 0.9459\n",
      "Epoch 241/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4357 - accuracy: 0.8924 - val_loss: 0.4101 - val_accuracy: 0.9459\n",
      "Epoch 242/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4402 - accuracy: 0.8976 - val_loss: 0.4091 - val_accuracy: 0.9459\n",
      "Epoch 243/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.4383 - accuracy: 0.9028 - val_loss: 0.4080 - val_accuracy: 0.9459\n",
      "Epoch 244/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4355 - accuracy: 0.8976 - val_loss: 0.4070 - val_accuracy: 0.9459\n",
      "Epoch 245/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4460 - accuracy: 0.9013 - val_loss: 0.4060 - val_accuracy: 0.9459\n",
      "Epoch 246/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4330 - accuracy: 0.9013 - val_loss: 0.4049 - val_accuracy: 0.9459\n",
      "Epoch 247/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4276 - accuracy: 0.9117 - val_loss: 0.4038 - val_accuracy: 0.9730\n",
      "Epoch 248/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4246 - accuracy: 0.9169 - val_loss: 0.4030 - val_accuracy: 0.9730\n",
      "Epoch 249/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4254 - accuracy: 0.9206 - val_loss: 0.4022 - val_accuracy: 0.9730\n",
      "Epoch 250/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4315 - accuracy: 0.9154 - val_loss: 0.4009 - val_accuracy: 0.9730\n",
      "Epoch 251/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4268 - accuracy: 0.9154 - val_loss: 0.3990 - val_accuracy: 0.9730\n",
      "Epoch 252/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4259 - accuracy: 0.9206 - val_loss: 0.3963 - val_accuracy: 0.9730\n",
      "Epoch 253/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4236 - accuracy: 0.9154 - val_loss: 0.3941 - val_accuracy: 0.9730\n",
      "Epoch 254/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4202 - accuracy: 0.9013 - val_loss: 0.3925 - val_accuracy: 0.9730\n",
      "Epoch 255/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4196 - accuracy: 0.9154 - val_loss: 0.3918 - val_accuracy: 0.9730\n",
      "Epoch 256/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.4211 - accuracy: 0.9206 - val_loss: 0.3910 - val_accuracy: 0.9730\n",
      "Epoch 257/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4171 - accuracy: 0.9206 - val_loss: 0.3901 - val_accuracy: 0.9730\n",
      "Epoch 258/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.4185 - accuracy: 0.9154 - val_loss: 0.3887 - val_accuracy: 0.9730\n",
      "Epoch 259/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.4110 - accuracy: 0.9206 - val_loss: 0.3865 - val_accuracy: 0.9730\n",
      "Epoch 260/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4184 - accuracy: 0.9206 - val_loss: 0.3843 - val_accuracy: 0.9730\n",
      "Epoch 261/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4163 - accuracy: 0.9206 - val_loss: 0.3830 - val_accuracy: 0.9730\n",
      "Epoch 262/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.4161 - accuracy: 0.9154 - val_loss: 0.3823 - val_accuracy: 0.9730\n",
      "Epoch 263/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.4132 - accuracy: 0.9258 - val_loss: 0.3821 - val_accuracy: 0.9730\n",
      "Epoch 264/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4110 - accuracy: 0.9206 - val_loss: 0.3822 - val_accuracy: 1.0000\n",
      "Epoch 265/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.4104 - accuracy: 0.9154 - val_loss: 0.3825 - val_accuracy: 1.0000\n",
      "Epoch 266/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4085 - accuracy: 0.9310 - val_loss: 0.3833 - val_accuracy: 1.0000\n",
      "Epoch 267/300\n",
      "2/2 [==============================] - 0s 45ms/step - loss: 0.4023 - accuracy: 0.9154 - val_loss: 0.3843 - val_accuracy: 1.0000\n",
      "Epoch 268/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.4018 - accuracy: 0.9065 - val_loss: 0.3837 - val_accuracy: 1.0000\n",
      "Epoch 269/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.4036 - accuracy: 0.9117 - val_loss: 0.3819 - val_accuracy: 1.0000\n",
      "Epoch 270/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.4115 - accuracy: 0.9013 - val_loss: 0.3803 - val_accuracy: 1.0000\n",
      "Epoch 271/300\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.4042 - accuracy: 0.9154 - val_loss: 0.3794 - val_accuracy: 1.0000\n",
      "Epoch 272/300\n",
      "2/2 [==============================] - 0s 41ms/step - loss: 0.3995 - accuracy: 0.9065 - val_loss: 0.3786 - val_accuracy: 1.0000\n",
      "Epoch 273/300\n",
      "2/2 [==============================] - 0s 42ms/step - loss: 0.3987 - accuracy: 0.9117 - val_loss: 0.3775 - val_accuracy: 1.0000\n",
      "Epoch 274/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3961 - accuracy: 0.9065 - val_loss: 0.3761 - val_accuracy: 1.0000\n",
      "Epoch 275/300\n",
      "2/2 [==============================] - 0s 43ms/step - loss: 0.4032 - accuracy: 0.9154 - val_loss: 0.3750 - val_accuracy: 1.0000\n",
      "Epoch 276/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3877 - accuracy: 0.9206 - val_loss: 0.3742 - val_accuracy: 1.0000\n",
      "Epoch 277/300\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.3954 - accuracy: 0.9065 - val_loss: 0.3729 - val_accuracy: 1.0000\n",
      "Epoch 278/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3937 - accuracy: 0.9013 - val_loss: 0.3708 - val_accuracy: 1.0000\n",
      "Epoch 279/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3884 - accuracy: 0.9206 - val_loss: 0.3689 - val_accuracy: 1.0000\n",
      "Epoch 280/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3976 - accuracy: 0.9154 - val_loss: 0.3676 - val_accuracy: 1.0000\n",
      "Epoch 281/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3922 - accuracy: 0.9154 - val_loss: 0.3658 - val_accuracy: 1.0000\n",
      "Epoch 282/300\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.3948 - accuracy: 0.9206 - val_loss: 0.3637 - val_accuracy: 1.0000\n",
      "Epoch 283/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3825 - accuracy: 0.9206 - val_loss: 0.3615 - val_accuracy: 1.0000\n",
      "Epoch 284/300\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.3813 - accuracy: 0.9206 - val_loss: 0.3597 - val_accuracy: 1.0000\n",
      "Epoch 285/300\n",
      "2/2 [==============================] - 0s 44ms/step - loss: 0.3891 - accuracy: 0.9258 - val_loss: 0.3579 - val_accuracy: 1.0000\n",
      "Epoch 286/300\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.3955 - accuracy: 0.9206 - val_loss: 0.3564 - val_accuracy: 1.0000\n",
      "Epoch 287/300\n",
      "2/2 [==============================] - 0s 46ms/step - loss: 0.3854 - accuracy: 0.9206 - val_loss: 0.3550 - val_accuracy: 1.0000\n",
      "Epoch 288/300\n",
      "2/2 [==============================] - 0s 51ms/step - loss: 0.3828 - accuracy: 0.9154 - val_loss: 0.3536 - val_accuracy: 1.0000\n",
      "Epoch 289/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3784 - accuracy: 0.9206 - val_loss: 0.3518 - val_accuracy: 1.0000\n",
      "Epoch 290/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3785 - accuracy: 0.9258 - val_loss: 0.3500 - val_accuracy: 1.0000\n",
      "Epoch 291/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3824 - accuracy: 0.9154 - val_loss: 0.3479 - val_accuracy: 1.0000\n",
      "Epoch 292/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3827 - accuracy: 0.9154 - val_loss: 0.3456 - val_accuracy: 1.0000\n",
      "Epoch 293/300\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.3736 - accuracy: 0.9258 - val_loss: 0.3438 - val_accuracy: 1.0000\n",
      "Epoch 294/300\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.3773 - accuracy: 0.9258 - val_loss: 0.3426 - val_accuracy: 1.0000\n",
      "Epoch 295/300\n",
      "2/2 [==============================] - 0s 76ms/step - loss: 0.3751 - accuracy: 0.9258 - val_loss: 0.3422 - val_accuracy: 1.0000\n",
      "Epoch 296/300\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.3791 - accuracy: 0.9206 - val_loss: 0.3424 - val_accuracy: 1.0000\n",
      "Epoch 297/300\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.3696 - accuracy: 0.9206 - val_loss: 0.3423 - val_accuracy: 1.0000\n",
      "Epoch 298/300\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.3767 - accuracy: 0.9206 - val_loss: 0.3418 - val_accuracy: 1.0000\n",
      "Epoch 299/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3742 - accuracy: 0.9206 - val_loss: 0.3416 - val_accuracy: 1.0000\n",
      "Epoch 300/300\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.3705 - accuracy: 0.9013 - val_loss: 0.3419 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# training the model \n",
    "history = model.fit(X_train, Y_oh_train, validation_data=(X_val,Y_oh_val),batch_size= 64, epochs= 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss (cross-entropy and accuracy): [0.5092122554779053, 0.8947368264198303]\n",
      "\n",
      "Layer 0\n",
      "Bias:\n",
      " [-0.08809545  0.          0.          0.48690903 -0.01417454]\n",
      "W:\n",
      " [[ 0.5776167  -0.7110878   0.58891964  0.14589913  0.8008287 ]\n",
      " [-0.32301527 -0.34411922 -0.54512966  0.6333156  -0.4935053 ]\n",
      " [ 1.2745903  -0.16416621 -0.4181727   0.2221433   0.22858764]\n",
      " [ 0.33718243 -0.34418485 -0.28657013 -0.18651731  0.8654781 ]]\n",
      "\n",
      "Layer 1\n",
      "Bias:\n",
      " [ 0.          0.0971528  -0.05379407 -0.01227745  0.314826   -0.03791562\n",
      " -0.04425772  0.13917144  0.40599108  0.563935  ]\n",
      "W:\n",
      " [[-0.18173245  0.8852496   1.0299165   0.08514076 -0.52131885 -0.37582618\n",
      "   0.48911723  0.34116557 -0.3597835  -0.38313845]\n",
      " [ 0.06115162  0.52945477  0.01633     0.2658232  -0.5555092  -0.549887\n",
      "  -0.4155826  -0.50716543  0.4199093   0.08533353]\n",
      " [ 0.58839995 -0.26009998  0.5277527   0.223234   -0.60799026  0.4420007\n",
      "   0.51593393  0.5619746  -0.38249296  0.33075225]\n",
      " [-0.21845096 -0.1166941   0.08124357 -0.0525332   0.7787063  -0.1833263\n",
      "  -0.65794855 -0.17733055  0.8863344   0.9296285 ]\n",
      " [-0.36930177  0.5129329   0.698128   -0.2875559  -0.04865344  0.4006864\n",
      "  -0.3230226   0.14844058 -0.34430894 -0.63182545]]\n",
      "\n",
      "Layer 2\n",
      "Bias:\n",
      " [ 0.16332823 -0.01990738 -0.16717178]\n",
      "W:\n",
      " [[-0.5755674   0.16358757 -0.5260277 ]\n",
      " [-1.1070918   0.17210634  0.5216966 ]\n",
      " [-1.1632438  -0.34657508 -0.23309295]\n",
      " [-0.02917935  0.562698   -0.10949272]\n",
      " [ 0.7768383  -0.0944958  -0.9022597 ]\n",
      " [-0.01686284  0.04751191 -0.27325702]\n",
      " [-0.47439045 -0.41856903  0.15455806]\n",
      " [ 0.09311332  0.01173378 -0.3850193 ]\n",
      " [ 0.72178537  0.15257487 -0.8757145 ]\n",
      " [ 0.815822   -0.2806541  -0.68558925]]\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, Y_oh_test, verbose=0)\n",
    "print('Test loss (cross-entropy and accuracy):',loss)\n",
    "print()\n",
    "W = model.get_weights()\n",
    "for ii in range(len(W)//2):\n",
    "    print(\"Layer %d\" %ii)\n",
    "    print('Bias:\\n', W[2*ii + 1])\n",
    "    print('W:\\n', W[2*ii])\n",
    "    print()\n",
    "\n",
    "plt.plot(history.history['loss'], label = \"Train loss\")\n",
    "plt.plot(history.history['val_loss'], label = \"Val loss\")\n",
    "plt.xlabel(\"Epoch (iteration)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'], label = \"Train accuarcy\")\n",
    "plt.plot(history.history['val_accuracy'], label = \"Val accuarcy\")\n",
    "plt.xlabel(\"Epoch (iteration)\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References for creating this jupyter notebook \n",
    "\n",
    "1) https://keras.io/guides/functional_api/\n",
    "\n",
    "2) https://keras.io/api/models/sequential/\n",
    "\n",
    "3) https://keras.io/api/models/\n",
    "\n",
    "4) https://towardsdatascience.com/3-ways-to-create-a-machine-learning-model-with-keras-and-tensorflow-2-0-de09323af4d3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Thanks to Kashyap Patel who helped develop this tutorial!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
